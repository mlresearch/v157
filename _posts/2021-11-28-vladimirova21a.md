---
title: Bayesian neural network unit priors and generalized Weibull-tail property
section: Contributed Papers
crossref: acml21
abstract: 'The connection between Bayesian neural networks and Gaussian processes
  gained a lot of attention in the last few years. Hidden units are proven to follow
  a Gaussian process limit when the layer width tends to infinity. Recent work has
  suggested that finite Bayesian neural networks may outperform their infinite counterparts
  because they adapt their internal representations flexibly. To establish solid ground
  for future research on finite-width neural networks, our goal is to study the prior
  induced on hidden units. Our main result is an accurate description of hidden units
  tails which shows that unit priors become heavier-tailed going deeper, thanks to
  the introduced notion of generalized Weibull-tail. This finding sheds light on the
  behavior of hidden units of finite Bayesian neural networks. '
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: vladimirova21a
month: 0
tex_title: "{B}ayesian neural network unit priors and generalized {W}eibull-tail property"
firstpage: 1397
lastpage: 1412
page: 1397-1412
order: 1397
cycles: false
bibtex_author: Vladimirova, Mariia and Arbel, Julyan and Girard, St\'ephane
author:
- given: Mariia
  family: Vladimirova
- given: Julyan
  family: Arbel
- given: St√©phane
  family: Girard
date: 2021-11-28
address:
container-title: Proceedings of The 13th Asian Conference on Machine Learning
volume: '157'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 11
  - 28
pdf: https://proceedings.mlr.press/v157/vladimirova21a/vladimirova21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
