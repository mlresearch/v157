---
title: Multi-factor Memory Attentive Model for Knowledge Tracing
section: Contributed Papers
crossref: acml21
abstract: The traditional knowledge tracing with neural network usually embeds the
  required information and predicates the knowledge proficiency by embedded information.
  Only few information, however, is considered in traditional methods, such as the
  information of exercises in terms of concept. In this paper, we propose a multi-factor
  memory attentive model for knowledge tracing (MMAKT). In terms of Neural Cognitive
  Diagnosis (NeuralCD) framework, MMAKT introduces the factors of the knowledge concept
  relevancy, the difficulty of each concept, the discrimination among exercises and
  the studentâ€™s proficiency to construct interaction vectors.  Moreover, in order
  to achieve more accurate prediction precision, MMAKT introduces attention mechanism
  to enhance the expression of historical relationship between interactions. With
  the experiments on the real-world datasets, MMAKT shows better performance of knowledge
  tracing and prediction in comparision with the state-of-the-art approaches.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu21c
month: 0
tex_title: Multi-factor Memory Attentive Model for Knowledge Tracing
firstpage: 856
lastpage: 869
page: 856-869
order: 856
cycles: false
bibtex_author: Liu, Congjie and Li, Xiaoguang
author:
- given: Congjie
  family: Liu
- given: Xiaoguang
  family: Li
date: 2021-11-28
address:
container-title: Proceedings of The 13th Asian Conference on Machine Learning
volume: '157'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 11
  - 28
pdf: https://proceedings.mlr.press/v157/liu21c/liu21c.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
