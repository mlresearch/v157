---
title: Multi-task Actor-Critic with Knowledge Transfer via a Shared Critic
section: Contributed Papers
crossref: acml21
abstract: Multi-task actor-critic is a learning paradigm proposed in the literature
  to improve the learning efficiency of multiple actor-critics by sharing the learned
  policies across tasks while the reinforcement learning progresses online. However,
  existing multi-task actor-critic algorithms can only handle reinforcement learning
  tasks within the same problem domain, they may fail in cases where tasks possessing
  diverse state-action spaces. Taking this cue, in this paper, we embark a study on
  multi-task actor-critic with knowledge transfer via a share critic to enable the
  multi-task learning of actor-critic in heterogeneous state-action environments.
  Further, for efficient learning of the proposed multi-task actor-critic, a new formula
  for calculating the gradient of the actor network is also presented. To evaluate
  the performance of our approach, comprehensive empirical studies on continuous robotic
  tasks with different numbers of links. The experimental results confirmed the effectiveness
  of the proposed multi-task actor-critic algorithm.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang21b
month: 0
tex_title: Multi-task Actor-Critic with Knowledge Transfer via a Shared Critic
firstpage: 580
lastpage: 593
page: 580-593
order: 580
cycles: false
bibtex_author: Zhang, Gengzhi and Feng, Liang and Hou, Yaqing
author:
- given: Gengzhi
  family: Zhang
- given: Liang
  family: Feng
- given: Yaqing
  family: Hou
date: 2021-11-28
address:
container-title: Proceedings of The 13th Asian Conference on Machine Learning
volume: '157'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 11
  - 28
pdf: https://proceedings.mlr.press/v157/zhang21b/zhang21b.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
