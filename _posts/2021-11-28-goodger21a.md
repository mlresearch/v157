---
title: Language Representations for Generalization in Reinforcement Learning
section: Contributed Papers
crossref: acml21
abstract: The choice of state and action representation in Reinforcement Learning
  (RL) has a significant effect on agent performance for the training task.  But its
  relationship with generalization to new tasks is under-explored.  One approach to
  improving generalization investigated here is the use of language as a representation.
  We compare vector-states and discrete-actions to language representations. We find
  the agents using language representations generalize better and could solve tasks
  with more entities, new entities, and more complexity than seen in the training
  task. We attribute this to the compositionality of language.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: goodger21a
month: 0
tex_title: Language Representations for Generalization in Reinforcement Learning
firstpage: 390
lastpage: 405
page: 390-405
order: 390
cycles: false
bibtex_author: Goodger, Nikolaj and Vamplew, Peter and Foale, Cameron and Dazeley,
  Richard
author:
- given: Nikolaj
  family: Goodger
- given: Peter
  family: Vamplew
- given: Cameron
  family: Foale
- given: Richard
  family: Dazeley
date: 2021-11-28
address:
container-title: Proceedings of The 13th Asian Conference on Machine Learning
volume: '157'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 11
  - 28
pdf: https://proceedings.mlr.press/v157/goodger21a/goodger21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
