---
title: Robust Domain Randomised Reinforcement Learning through Peer-to-Peer Distillation
section: Contributed Papers
crossref: acml21
abstract: In reinforcement learning, domain randomisation is a popular technique for
  learning general policies that are robust to new environments and domain-shifts
  at deployment. However, naively aggregating information from randomised domains
  may lead to high variances in gradient estimation and sub-optimal policies. To address
  this issue, we present a peer-to-peer online distillation strategy for reinforcement
  learning termed P2PDRL, where multiple learning agents are each assigned to a different
  environment, and then exchange knowledge through mutual regularisation based on
  Kullbackâ€“Leibler divergence. Our experiments on continuous control tasks show that
  P2PDRL enables robust learning across a wider randomisation distribution than baselines,
  and more robust generalisation performance to new environments at testing.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhao21b
month: 0
tex_title: Robust Domain Randomised Reinforcement Learning through Peer-to-Peer Distillation
firstpage: 1237
lastpage: 1252
page: 1237-1252
order: 1237
cycles: false
bibtex_author: Zhao, Chenyang and Hospedales, Timothy
author:
- given: Chenyang
  family: Zhao
- given: Timothy
  family: Hospedales
date: 2021-11-28
address:
container-title: Proceedings of The 13th Asian Conference on Machine Learning
volume: '157'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 11
  - 28
pdf: https://proceedings.mlr.press/v157/zhao21b/zhao21b.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
