---
title: Layer-Wise Neural Network Compression via Layer Fusion
section: Contributed Papers
crossref: acml21
abstract: " This paper proposes \\textit{layer fusion} - a model compression technique
  that discovers which weights to combine and then fuses weights of similar fully-connected,
  convolutional and attention layers. Layer fusion can significantly reduce the number
  of layers of the original network with little additional computation overhead, while
  maintaining competitive performance. From experiments on CIFAR-10, we find that
  various deep convolution neural networks can remain within 2% accuracy points of
  the original networks up to a compression ratio of 3.33 when iteratively retrained
  with layer fusion. For experiments on the WikiText-2 language modelling dataset,
  we compress Transformer models to 20% of their original size while being within
  5 perplexity points of the original network. We also find that other well-established
  compression techniques can achieve competitive performance when compared to their
  original networks given a sufficient number of retraining steps. Generally, we observe
  a clear inflection point in performance as the amount of compression increases,
  suggesting a bound on the amount of compression that can be achieved before an exponential
  degradation in performance.  "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: o-neill21a
month: 0
tex_title: Layer-Wise Neural Network Compression via Layer Fusion
firstpage: 1381
lastpage: 1396
page: 1381-1396
order: 1381
cycles: false
bibtex_author: O'Neill, James and V. Steeg, Greg and Galstyan, Aram
author:
- given: James
  family: Oâ€™Neill
- given: Greg
  family: V. Steeg
- given: Aram
  family: Galstyan
date: 2021-11-28
address:
container-title: Proceedings of The 13th Asian Conference on Machine Learning
volume: '157'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 11
  - 28
pdf: https://proceedings.mlr.press/v157/o-neill21a/o-neill21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
