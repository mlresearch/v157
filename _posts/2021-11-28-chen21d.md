---
title: 'Relation Also Need Attention: Integrating Relation Information Into Image
  Captioning'
section: Contributed Papers
crossref: acml21
abstract: Image captioning methods with attention mechanism are leading this field,
  especially models with global and local attention. But there are few conventional
  models to integrate the relationship information between various regions of the
  image. In this paper, this kind of relationship features are embedded into the fused
  attention mechanism to explore the internal visual and semantic relations between
  different object regions. Besides, to alleviate the exposure bias problem and make
  the training process more efficient, we combine Generative Adversarial Network with
  Reinforcement Learning and employ the greedy decoding method to generate a dynamic
  baseline reward for self-critical training. Finally, experiments on MSCOCO datasets
  show that the model can generate more accurate and vivid image captioning sentences
  and perform better in multiple prevailing metrics than the previous advanced models.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen21d
month: 0
tex_title: 'Relation Also Need Attention: Integrating Relation Information Into Image
  Captioning'
firstpage: 1537
lastpage: 1552
page: 1537-1552
order: 1537
cycles: false
bibtex_author: Chen, Tianyu and Li, Zhixin and Xian, Tiantao and Zhang, Canlong and
  Ma, Huifang
author:
- given: Tianyu
  family: Chen
- given: Zhixin
  family: Li
- given: Tiantao
  family: Xian
- given: Canlong
  family: Zhang
- given: Huifang
  family: Ma
date: 2021-11-28
address:
container-title: Proceedings of The 13th Asian Conference on Machine Learning
volume: '157'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 11
  - 28
pdf: https://proceedings.mlr.press/v157/chen21d/chen21d.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
